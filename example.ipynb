{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bb23716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from event_table import Event_Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6829db43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read parquet succesfully!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Event_Table.__init__() missing 2 required positional arguments: 'calibration_results' and 'calibrated'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m loaded = \u001b[43mEvent_Table\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfitres_10_11_2_rep1.parquet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mROI\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mMedium\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mInstrument\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mRefeyn OneMP\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneeds_calibration\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chem-shug7580\\Projects\\Calibration_and_EMD\\event_table.py:63\u001b[39m, in \u001b[36mEvent_Table.from_path\u001b[39m\u001b[34m(cls, file_path, ROI, Instrument, needs_calibration)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mROI name cannot be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mROI\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, only Medium, Small, Full or Regular\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mframe\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_det\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43my\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx_det\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mx\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontrasts_det\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontrasts_det\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontrasts_det\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontrasts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontrasts\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx_fit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mx_fit\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_fit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43my_fit\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontrasts_se\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontrasts_se\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43mr2_fit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr2_fit\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43mres_fit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mres_fit\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mx\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43my\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmasses_kDa\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmasses_kDa\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmasses_kDa\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcalibration_required\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneeds_calibration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43minstrument_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mInstrument\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mROI_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mROI\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: Event_Table.__init__() missing 2 required positional arguments: 'calibration_results' and 'calibrated'"
     ]
    }
   ],
   "source": [
    "loaded = Event_Table.from_path(file_path='fitres_10_11_2_rep1.parquet', ROI='Medium', Instrument='Refeyn OneMP', needs_calibration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "501d7b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in loaded: (13)\n",
      "00: 'frame'   --> U+0066 U+0072 U+0061 U+006D U+0065\n",
      "01: 'y_det'   --> U+0079 U+005F U+0064 U+0065 U+0074\n",
      "02: 'x_det'   --> U+0078 U+005F U+0064 U+0065 U+0074\n",
      "03: 'contrasts_det'   --> U+0063 U+006F U+006E U+0074 U+0072 U+0061 U+0073 U+0074 U+0073 U+005F U+0064 U+0065 U+0074\n",
      "04: 'contrasts'   --> U+0063 U+006F U+006E U+0074 U+0072 U+0061 U+0073 U+0074 U+0073\n",
      "05: 'x_fit'   --> U+0078 U+005F U+0066 U+0069 U+0074\n",
      "06: 'y_fit'   --> U+0079 U+005F U+0066 U+0069 U+0074\n",
      "07: 'contrasts_se'   --> U+0063 U+006F U+006E U+0074 U+0072 U+0061 U+0073 U+0074 U+0073 U+005F U+0073 U+0065\n",
      "08: 'r2_fit'   --> U+0072 U+0032 U+005F U+0066 U+0069 U+0074\n",
      "09: 'res_fit'   --> U+0072 U+0065 U+0073 U+005F U+0066 U+0069 U+0074\n",
      "10: 'x'   --> U+0078\n",
      "11: 'y'   --> U+0079\n",
      "12: 'masses_kDa'   --> U+006D U+0061 U+0073 U+0073 U+0065 U+0073 U+005F U+006B U+0044 U+0061\n",
      "\n",
      "Columns in standard: (13)\n",
      "00: 'frame'   --> U+0066 U+0072 U+0061 U+006D U+0065\n",
      "01: 'y_det'   --> U+0079 U+005F U+0064 U+0065 U+0074\n",
      "02: 'x_det,'   --> U+0078 U+005F U+0064 U+0065 U+0074 U+002C\n",
      "03: 'contrasts_det'   --> U+0063 U+006F U+006E U+0074 U+0072 U+0061 U+0073 U+0074 U+0073 U+005F U+0064 U+0065 U+0074\n",
      "04: 'contrasts'   --> U+0063 U+006F U+006E U+0074 U+0072 U+0061 U+0073 U+0074 U+0073\n",
      "05: 'x_fit'   --> U+0078 U+005F U+0066 U+0069 U+0074\n",
      "06: 'y_fit'   --> U+0079 U+005F U+0066 U+0069 U+0074\n",
      "07: 'contrasts_se'   --> U+0063 U+006F U+006E U+0074 U+0072 U+0061 U+0073 U+0074 U+0073 U+005F U+0073 U+0065\n",
      "08: 'r2_fit'   --> U+0072 U+0032 U+005F U+0066 U+0069 U+0074\n",
      "09: 'res_fit'   --> U+0072 U+0065 U+0073 U+005F U+0066 U+0069 U+0074\n",
      "10: 'x'   --> U+0078\n",
      "11: 'y'   --> U+0079\n",
      "12: 'masses_kDa'   --> U+006D U+0061 U+0073 U+0073 U+0065 U+0073 U+005F U+006B U+0044 U+0061\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def inspect_column_names(df, label=\"df\"):\n",
    "    print(f\"Columns in {label}: ({len(df.columns)})\")\n",
    "    for i, c in enumerate(df.columns):\n",
    "        s = str(c)\n",
    "        cp = \" \".join(f\"U+{ord(ch):04X}\" for ch in s)\n",
    "        print(f\"{i:02d}: {repr(s)}   --> {cp}\")\n",
    "\n",
    "# load both: the loaded parquet & your standard csv used previously\n",
    "df_loaded = pd.read_parquet('fitres_10_11_2_rep1.parquet')\n",
    "df_standard = pd.read_csv('standard_event_table_format.csv')\n",
    "\n",
    "inspect_column_names(df_loaded, \"loaded\")\n",
    "print()\n",
    "inspect_column_names(df_standard, \"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c2b53b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup created at standard_event_table_format.csv.bak\n",
      "Header before cleaning:\n",
      "['frame,,\"y_det,\",\"x_det,\",\"contrasts_det,\",\"contrasts,\",\"x_fit,\",\"y_fit,\",\"contrasts_se,\",\"r2_fit,\",\"res_fit,\",\"x,\",\"y,\",masses_kDa']\n",
      "Header after cleaning:\n",
      "['frame,,\"y_det,\",\"x_det,\",\"contrasts_det,\",\"contrasts,\",\"x_fit,\",\"y_fit,\",\"contrasts_se,\",\"r2_fit,\",\"res_fit,\",\"x,\",\"y,\",masses_kDa']\n",
      "Cleaned file written to standard_event_table_format.csv (original backed up at standard_event_table_format.csv.bak)\n"
     ]
    }
   ],
   "source": [
    "# fix_standard_header_commas.py\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "STANDARD = Path(\"standard_event_table_format.csv\")\n",
    "BACKUP = STANDARD.with_suffix(\".csv.bak\")\n",
    "\n",
    "if not STANDARD.exists():\n",
    "    raise FileNotFoundError(f\"{STANDARD} not found\")\n",
    "\n",
    "# 1) Backup\n",
    "shutil.copy2(STANDARD, BACKUP)\n",
    "print(f\"Backup created at {BACKUP}\")\n",
    "\n",
    "# 2) Read file robustly (try csv, fallback to tsv if necessary)\n",
    "def try_read(path):\n",
    "    df = pd.read_csv(path, dtype=str)\n",
    "    # if many column names start or end with a comma, try reading as tab-separated (maybe it was TSV)\n",
    "    cols = list(df.columns)\n",
    "    if sum(1 for c in cols if isinstance(c, str) and (c.startswith('\"') or c.endswith(','))) > 0:\n",
    "        try:\n",
    "            df = pd.read_csv(path, sep=\"\\t\", dtype=str)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return df\n",
    "\n",
    "df = try_read(STANDARD)\n",
    "\n",
    "print(\"Header before cleaning:\")\n",
    "print(list(df.columns))\n",
    "\n",
    "# 3) Clean routine for column names\n",
    "def clean_col(c: str) -> str:\n",
    "    if c is None:\n",
    "        return \"\"\n",
    "    s = str(c)\n",
    "    # Remove surrounding double quotes if present\n",
    "    if s.startswith('\"') and s.endswith('\"'):\n",
    "        s = s[1:-1]\n",
    "    # Remove trailing commas that are part of the header string\n",
    "    s = re.sub(r',+$', '', s)\n",
    "    # Remove stray leading/trailing whitespace and invisible chars\n",
    "    s = re.sub(r'[\\uFEFF\\u200B-\\u200D\\r\\n\\t]', '', s).strip()\n",
    "    return s\n",
    "\n",
    "df.columns = [clean_col(c) for c in df.columns]\n",
    "\n",
    "print(\"Header after cleaning:\")\n",
    "print(list(df.columns))\n",
    "\n",
    "# 4) Write cleaned file back (no index, UTF-8 no BOM)\n",
    "df.to_csv(STANDARD, index=False, encoding=\"utf-8\")\n",
    "print(f\"Cleaned file written to {STANDARD} (original backed up at {BACKUP})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7c0c6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in standard (before):\n",
      "00: 'frame,'\n",
      "01: 'y_det,'\n",
      "02: 'x_det,'\n",
      "03: 'contrasts_det,'\n",
      "04: 'contrasts,'\n",
      "05: 'x_fit,'\n",
      "06: 'y_fit,'\n",
      "07: 'contrasts_se,'\n",
      "08: 'r2_fit,'\n",
      "09: 'res_fit,'\n",
      "10: 'x,'\n",
      "11: 'y,'\n",
      "12: 'masses_kDa'\n",
      "\n",
      "Backup saved to: standard_event_table_format.csv.bak\n",
      "\n",
      "Columns in standard (after):\n",
      "00: 'frame,'\n",
      "01: 'y_det,'\n",
      "02: 'x_det,'\n",
      "03: 'contrasts_det,'\n",
      "04: 'contrasts,'\n",
      "05: 'x_fit,'\n",
      "06: 'y_fit,'\n",
      "07: 'contrasts_se,'\n",
      "08: 'r2_fit,'\n",
      "09: 'res_fit,'\n",
      "10: 'x,'\n",
      "11: 'y,'\n",
      "12: 'masses_kDa'\n",
      "\n",
      "Column differences (visual):\n",
      "Removed (old representations):\n",
      "   '\\tcontrasts'\n",
      "   '\\tcontrasts_det'\n",
      "   '\\tcontrasts_se'\n",
      "   '\\tmasses_kDa'\n",
      "   '\\tr2_fit'\n",
      "   '\\tres_fit'\n",
      "   '\\tx'\n",
      "   '\\tx_det'\n",
      "   '\\tx_fit'\n",
      "   '\\ty'\n",
      "   '\\ty_det'\n",
      "   '\\ty_fit'\n",
      "   'frame'\n",
      "Added (new representations):\n",
      "   'contrasts,'\n",
      "   'contrasts_det,'\n",
      "   'contrasts_se,'\n",
      "   'frame,'\n",
      "   'masses_kDa'\n",
      "   'r2_fit,'\n",
      "   'res_fit,'\n",
      "   'x,'\n",
      "   'x_det,'\n",
      "   'x_fit,'\n",
      "   'y,'\n",
      "   'y_det,'\n",
      "   'y_fit,'\n",
      "\n",
      "Cleaned standard file written back to: standard_event_table_format.csv\n"
     ]
    }
   ],
   "source": [
    "# clean_standard_columns.py\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "STANDARD_PATH = Path(\"standard_event_table_format.csv\")\n",
    "BACKUP_PATH = STANDARD_PATH.with_suffix(\".csv.bak\")\n",
    "\n",
    "def try_read(path: Path):\n",
    "    \"\"\"Try to read as CSV, if columns look tab-prefixed try reading as TSV.\"\"\"\n",
    "    df = pd.read_csv(path, dtype=str)\n",
    "    # quick check: if many column names start with '\\t', try sep='\\t'\n",
    "    cols = list(df.columns)\n",
    "    if sum(1 for c in cols if isinstance(c, str) and c.startswith(\"\\t\")) > 0:\n",
    "        df = pd.read_csv(path, sep=\"\\t\", dtype=str)\n",
    "    return df\n",
    "\n",
    "def clean_name(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = str(s)\n",
    "    # remove BOM and common invisible characters including tabs/newlines/zero-width\n",
    "    s = re.sub(r'[\\uFEFF\\u200B-\\u200D\\u0009\\u000A\\u000D]', '', s)\n",
    "    s = s.strip()\n",
    "    return s\n",
    "\n",
    "def main():\n",
    "    if not STANDARD_PATH.exists():\n",
    "        raise FileNotFoundError(f\"{STANDARD_PATH} not found in current directory.\")\n",
    "\n",
    "    # 1. Read (try csv, fall back to tsv)\n",
    "    df = try_read(STANDARD_PATH)\n",
    "\n",
    "    # 2. Show before\n",
    "    print(\"Columns in standard (before):\")\n",
    "    for i, c in enumerate(df.columns):\n",
    "        print(f\"{i:02d}: {repr(c)}\")\n",
    "\n",
    "    # 3. Backup original\n",
    "    shutil.copy2(STANDARD_PATH, BACKUP_PATH)\n",
    "    print(f\"\\nBackup saved to: {BACKUP_PATH}\")\n",
    "\n",
    "    # 4. Clean column names\n",
    "    cleaned = [clean_name(c) for c in df.columns]\n",
    "    df.columns = cleaned\n",
    "\n",
    "    # 5. Show after + diff\n",
    "    print(\"\\nColumns in standard (after):\")\n",
    "    for i, c in enumerate(df.columns):\n",
    "        print(f\"{i:02d}: {repr(c)}\")\n",
    "\n",
    "    before_set = set(repr(c) for c in pd.read_csv(BACKUP_PATH, dtype=str).columns)\n",
    "    after_set = set(repr(c) for c in df.columns)\n",
    "    removed = before_set - after_set\n",
    "    added = after_set - before_set\n",
    "    if removed or added:\n",
    "        print(\"\\nColumn differences (visual):\")\n",
    "        if removed:\n",
    "            print(\"Removed (old representations):\")\n",
    "            for r in sorted(removed):\n",
    "                print(\"  \", r)\n",
    "        if added:\n",
    "            print(\"Added (new representations):\")\n",
    "            for a in sorted(added):\n",
    "                print(\"  \", a)\n",
    "    else:\n",
    "        print(\"\\nNo set-difference detected (names normalized).\")\n",
    "\n",
    "    # 6. Overwrite standard file as CSV with UTF-8 (no BOM), no index\n",
    "    df.to_csv(STANDARD_PATH, index=False, encoding=\"utf-8\")\n",
    "    print(f\"\\nCleaned standard file written back to: {STANDARD_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
